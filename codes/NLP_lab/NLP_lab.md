# 毕设实验
## 思路
* TF-IDF
1. 安装NLP相关包，建立词频表
2. 使用命令行进行文件读写处理，去停用词
3. 将论文题目与摘要拼接为整体，逐条分词并使用TF-IDF处理后作为论文向量
4. 使用余弦相似度进行分类或推荐

* Word2Vec
1. 安装NLP相关包并建立词频表，进行数据预处理，将论文题目与摘要合成整体
2. 使用英文维基百科语料训练词向量，并使用深度学习中Word2Vec进行向量化
3. 将词向量内容读入并建立对应自己语料库的词汇+向量表：从词嵌入中提取出的所需的模型数量，同时适当减少词语的特征维度，**并将词嵌入模型迁移到我们小训练集的新任务上**
4. 利用相应的词汇表及向量进行K-means聚类（使用SKlearn)
5. 同一类别的词当作一个词使用TF-IDF进行处理作为论文向量
6. 将聚类后的词汇进行TF-IDF算法计算（改进稀疏矩阵，提高运行效率）
7. 余弦相似度计算
8. 实验结果：当输入想要计算的论文记录时，算法将遍历所有论文记录，并降序输出相似度最高的十条记录作为推荐

## 代码
1. tfidf.py:TF-IDF方式表示论文向量，结果为稀疏矩阵（维数过多导致可读性极差，待改进）
2. vec_tfidf.py:word2vec+TF-IDF方式表示论文向量，使用深度学习算法————词嵌入方式降维，论文矩阵明显可读性增强，运行效率提高
3. load.py:提取基于英文wiki百科语料训练好后的词向量,以单词+向量的形式存储在数组中，共计2210620条（vec_deal.pkl)
4. deal.py:将训练后的词向量迁移到自己的数据集上，得到属于自己论文语料库的词向量,共计16493条（values.pkl)
5. kmeans.py:将自己语料库的词向量进行K-means聚类，类别相似的词汇聚为一组（kmeans.pkl)
6. change.py:将原论文数据分词后的数据集使用数字替换单词（dc.pkl:单词：对应其类别的序号）（res.pkl:每条论文记录：[单词1(组别1），单词2（组别2），单词3（组别3）]）
7. cos.py:计算论文向量间余弦相似度，相似度越接近于1，说明两个文本之间相似程度越大
(待实现:输入想要计算的论文记录，遍历所有内容降序输出相似度最高的十条记录作为推荐）


## 文档
* 数据预处理：
1. node_information.csv：原始数据（论文序号，发表年份，题目，作者，期刊，摘要）
2. text.pkl:论文的题目和摘要（文本，以数组形式分条记录）
3. words.pkl:分词后的text（单词，以数组形式分条记录）
* 向量化：
1. vec_words.pkl:词向量的单词部分（单词，数组）
2. vectors.pkl:词向量的向量部分（向量，数组）
3. vec_deal.pkl:从词嵌入中提取出的词向量模型（词+向量（50维），数组）
4. word_freq:词频表（单词+出现次数）
5. value_words:词频表（单词，数组）
6. embeddings.pkl:属于自己的词向量一开始是以“词+词向量（字符串）”的形式存储，需要转换为词的向量矩阵形式。故先建立词表，再根据标号建立与每个词所对应的矩阵（矩阵中词向量为数字形式）
7. vocab.pkl:当前数据集中出现过的所有单词
8. word2id.pkl:为单词赋好标号，用数字替换单词以方便向量化


## 实验结果
1. 得出论文向量（词汇矩阵形式）[TF-IDF/**Word2Vec**]
2. 针对某一论文向量对其他论文向量与之进行余弦相似度计算，将结果降序排列
3. 越接近1，说明这两篇论文之间越相似
4. 最终实现基于内容的科技文献推荐算法

